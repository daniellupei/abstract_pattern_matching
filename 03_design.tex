\section{Design}

We consider patterns specified as a symbolic finite automata where each
transition has a guard (propositional formula) whose predicates test the
currently considered event against constants as well as events matched by
preceding transitions.
   
Pattern matching algorithms require data sorted on time.
In a map-reduce framework this makes the reducer the main bottleneck of the
analysis, both at the network level (large amounts of shuffled data) and at
the processing level (in case of data-skew).



We propose to significantly reduce the amount of data fed into the pattern
matcher (reducer) by dropping in a map phase all the events that cannot take
part in a successful match.

To do so we design a set of filters that while conservative, closely match the
semantics of the patterns analyzed.
We propose three levels of abstraction.
The first enforces the join constraints between different transitions as
expressed by join predicates within the transition guards.
The second one further imposes time windowing constraints (all events of a
successful match must occur within a timeout of the first event in the match).
Finally the last one enforces ordering constraints between {\em consecutive}
transitions of the pattern.

In our approach we leverage the fact that a large class of symbolic finite
automata fit within the fragment of star-free languages which
have a corresponding FOL formula (possibly with counting quantifiers).
Whenever that is not the case we can narrow the scope of our filters to the
sections of the pattern that do.
 
We relax these FOL formulas to produce precise filters, one per transition, 
that can be evaluated independently on each mapper.
Finally we further coarsen these filters to a set of relaxed filters
that can be collected and tested in a time and space efficient manner (eg. bloom
filters, time-interval maps).

We explore the trade-offs involved in the overheads incurred in building the
filters and their accuracy. 





\subsection{Precise filter generation}
\label{sec:data_abstraction}





\subsection{Symbolic filters via data abstraction}
\label{sec:data_abstraction}




\subsection{Predicate abstraction}
\label{sec:pred_abstraction}


We propose {\em predicate abstraction}, ie.\ the technique of strengthening the
precise filters by discarding some of their predicates, as a way of overcoming
the challenges that can arise when turning precise filters into symbolic filters
via data abstraction.
For example, it may happen that for some predicate types
(for eg. $x.Contains(y)$, where $x$, $y$ are strings) we simply cannot provide
any data abstraction, and even for those that we can, materializing and querying
those data abstractions might prove too expensive.

Predicate abstraction is an essential component of our approach
allowing us to strike the right balance between the data reduction that the
symbolic filters provide, on one hand, and the overheads introduced by their
data abstractions on the other.
For instance, we may choose to discard
predicates that have very low selectivity, i.e.\ the reduction in input data
that they provide does not justify the cost of enforcing them.
Similarly, one may turn to predicate abstraction when dealing with patterns with
a large number of join predicates or transitions, in order to mitigate the
increased overheads incurred by their data abstractions.










 
