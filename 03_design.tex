\section{Design}


We consider queries specified as a symbolic finite automaton where each
transition is annotated by a variable and a guard.
The variable is used to bind the fields of the currently considered event while 
the guard is a propositional formula in disjunctive normal form which decides 
whether the transition can be triggered or not.  
The atomic formulas of the guard are either {\em selection} predicates, which 
only reference the variable associated with the current transition,
or {\em join} predicates, which may also reference the variables of preceding 
transitions.
In particular, the guards of start transitions can only use selection 
predicates.  
   
Pattern matching algorithms require the input stream of events to be
(partially) sorted on time, while this is not always the case in practice due
to competing constraints of other stages in the data processing pipeline. 
Thus, evaluating pattern matching queries in a map-reduce framework usually 
adds a reduction step in order to sort the input, which can become the main 
bottleneck of the analysis, both at the network level (large amounts of 
shuffled data) and at the processing level (in case of data-skew).

The standard approach to minimize the cost of sorting/data shuffling has been 
to introduce a {\em preprocessing} phase which first filters the input based on 
the {\em selection} predicates in the transition guards, i.e.\ removes all 
events that do not satisfy the guard of at least one transition while ignoring 
its {\em join} predicates.
This {\em preprocessing} phase can significantly reduce both processing costs 
and latency since it takes linear time in the size of the input (as opposed to 
$O(nlogn)$ for sorting) and is embarrassingly parallel, i.e.\ scales out with 
the number of computing resources available.
Moreover, it can be merged with the previous operator in the data processing 
pipeline thus incurring no extra costs for materialization or data transfer.    


In our work we extend the opportunities for query plan optimizations across all 
the stages of the workload, beyond just pipelining the preprocessing phase of 
the pattern matcher, by leveraging the fact that a large class of symbolic 
finite automata have a corresponding relational calculus expression (possibly 
with counting quantifiers).
Whenever that is not the case we can narrow the scope of our optimizations to 
the sections of the pattern that do.
The resulting relational expressions can then be optimized within the scope of 
the entire (predominantly relational) workload based on decades of progress in 
relational optimizations.  
We remark that the translation to relational expressions is not limited only to 
acyclic symbolic automata, but also to automata with cycles of fixed length, 
i.e.\ each iteration of the cycle has the same number of transitions.
This class of symbolic automata is of particular importance as it includes the 
vast majority of patterns found in benchmarks and in industrial workloads.  


Even in the scenarios where the relational optimizer decides that using the 
pattern matcher leads to the most efficient query plan, we can leverage the 
relational expressions to generate a series of {\em abstract} filters that can 
dramatically increase the reduction ratio achieved by the preprocessing step by 
also taking advantage of the filtering power of {\em join} predicates (as 
opposed to just the {\em selection} predicates).   
Thus, in many cases we manage to discard most of the events that are guaranteed 
not to take part in a successful match and significantly reduce the amount of 
data fed into the pattern matcher.

We start from the relational formulas and produce {\em symbolic} filters for 
each transition, that retain only those events from the input which trigger 
that transition and take part in a complete match.
However in many cases these filters would be too expensive to build and 
evaluate as such.
Therefore, we coarsen them to obtain a set of {\em abstract} filters
that can be constructed and queried in a time and space efficient manner.
In particular, we make use of both {\em data} abstraction and {\em predicate} 
abstraction in order to generate filters that, while conservative, closely 
match the {\em symbolic} filters. 
We explore the trade-offs between the overheads incurred in building/querying
the filters and their accuracy. 


The derivation of abstract filters is not strictly tied to the ability to 
generate a semantically equivalent relational expression for a symbolic 
automaton. By adding the fixpoint construct, we are able to apply similar 
techniques to generate both the {\em symbolic} and the {\em abstract} 
filters.


\begin{comment}
We propose three levels of abstraction.
The first enforces the join constraints between different transitions as
expressed by join predicates within the transition guards.
The second one further imposes time windowing constraints (all events of a
successful match must occur within a timeout of the first event in the match).
Finally the last one enforces ordering constraints between {\em consecutive}
transitions of the pattern.
\end{comment}

\subsection{From automata to relational expressions}

We assume that patterns are specified in terms of symbolic finite automata and
we formally define a symbolic finite automaton as $\cA = (S, T, s_{start}, C),$ 
where $S$ is the set of states, $T$ is the set of transitions, $s_{start}$ is 
the initial state and $C$ is the set of completion (accepting) states.
Each transition is defined in terms of the tuple $(X, p_X, src, dst)$ where $X$ 
is the variable binding the event considered for that transition, $p_X$ is the 
guard deciding whether the transition is triggered or not, and $src$ and $dst$ 
are the transition's source and destination states.

{\bf Notation.}
We usually denote states by indices $i, j, k,$, and we abuse notation to refer 
to transitions using the variable name they introduce (eg. $X, Y, Z$).
In addition we refer to states and transitions also as nodes and edges, 
respectively, in the corresponding graph of an automaton.

To streamline the presentation we begin by considering automata with only
cycles of length 1 and we distinguish between cycle transitions and
non-cycle transitions.


The translation process produces one relational query $Q_i$ per state $i$, and 
the final relational expression of the automata is obtained by unioning all the 
queries generated for the automata's accepting nodes.
Evaluating query $Q_i$ over a set of events computes partial matches, i.e.\ 
sequences of events, corresponding to all the possible paths between the 
starting node and node $i$.
Therefore, if $i$ is the starting node then its query returns an empty sequence 
while if $i$ is an accepting node then it returns complete matches found in the 
input stream of events.
Moreover, the partial (complete) matches computed by $Q_i$ do not include the 
events matched against cycle transitions therefore have a bounded length. 

The schema of the queries we generate consist of a sequence of event variables, 
one for each non-cycle transition that may occur along its associated set of 
paths. 
If a transition is triggered within a partial match, then its corresponding 
variable is initialized by the event that triggered it, otherwise that variable 
is assigned null.


State queries $Q_i$ are defined as the union of transition queries $Q_X$ over 
all the incoming non-cycle transitions into state $i$, where each transition 
query $Q_X$ computes partial matches corresponding to the paths ending with 
transition $X$.
In turn, the $Q_X$ query corresponding to a non-cycle transition is defined as 
the join between node query $Q_k$ and the input relation of events, where $k$ 
is the source of the transition and each event considered is bound by event 
variable $X$.
The condition enforced by $Q_X$ consists of the guard $p_X$ along with the 
constraint that the timestamp of $X$ succeeds the last event in the partial 
match produced by $Q_k$.
Additionally, a nested query ensures that no other events 
exist between the last event matched by $Q_k$ and the event bound by $X$, 
except for events matching cycle transitions starting and ending in $k$.


The translation process iterates in topological order over the nodes of the DAG
obtained by ignoring the cycle transitions of the automaton.
At each node $i$, it first generates the queries for all its incoming
non-cycle transitions $Q_X$ and then $Q_i$ is defined as their union. 
The schema of $Q_i$ is established as the union of the schemas of the incoming 
transitions $Q_X$.


In order to perform this translation for all automata whose cycles have a fixed 
length ($\geq 1$), we first normalize them such that each cycle starts and ends 
with the same state.
More formally, the cycles of a normalized automata have a single incoming edge 
and a single outgoing edge and both of them enter and exit, respectively, the 
same node.
We remark, that cycles of fixed length cannot have transversal edges (paths), 
i.e.\ edges (paths) that connect non-adjacent nodes, as this would violate the 
restriction that each iteration of the cycle has the same length.

Given an automaton with a cycle that has multiple incoming and outgoing edges 
we first duplicate the cycle for each additional incoming edge. 
Then we duplicate the path between the starting and ending nodes of the cycle, 
where starting node of a cycle is defined as the destination of its incoming 
edge while the ending node is the source of the last of its outgoing edges. 
Finally, we change the source of each outgoing edge to be the corresponding 
node in the newly created path, resulting in a cycle whose incoming and 
outgoing edges have the same node as destination and source, respectively.
By applying this procedure to every cycle with multiple incoming and outgoing 
edges we obtain a normalized automaton.  
We remark that, while the resulting automaton may have multiple cycles starting 
and ending with the same node, all of those must also have the same length.


The only part of the translation process that changes when generalizing from 
automata with single edge cycles to normalized automata is the specification of 
transition queries $Q_X$, and in particular, the specification of its nested 
query should the source state of $X$ be the starting/ending point of a cycle.
We recall that in the case of cycles with a single transition $Y$ the nested 
query enforces that all events occurring in the interval between the last event 
in the partial match computed by $Q_k$ and the timestamp of event variable $X$ 
satisfy guard $p_Y$. 
By contrast, in the case of multi-edge fixed length cycles, for each event in 
the same interval we establish its position (based on  the count of events with 
smaller timestamps) and we ask that it satisfies the guard of the transition 
corresponding to that position in the cycle modulo the length of the cycle.
If multiple cycles initiate and conclude at the same node, we alternatively 
have to enforce that all events in an iteration satisfy the corresponding 
transition guards of a particular cycle.


\subsection{Symbolic filter generation}
\label{sec:prec_filter_generation}



After translating patterns into relational queries a host of relational 
optimizations become applicable, from column pruning and partial aggregation to
the selection of specific join algorithms.
In the following we detail our proposal for speeding up pattern matching in a 
distributed environment based on its representation in the relational world as 
a series of unions and joins.
More specifically, even though this representation may prove too expensive to 
evaluate directly, one can still use it to design filters meant to discard from 
the input (almost) all the events that do not participate in a complete match 
and thus vastly reduce the number of events ultimately processed by the pattern 
matching engine.
 
 % discuss difference between fields referenced by selection predicates and 
 %fields referenced by join predicates, and how the symbolic filters are 
 %concerned with the latter.


The first step in this process is to generate for each transition of the 
automaton a {\em symbolic} filter.
These filters are precise in the sense that they retain only the events  
guaranteed to appear in a successful match.
While it is understood that constructing and applying such filters is 
prohibitively expensive, we discuss them nonetheless as they are essential in 
guiding the design of {\em abstract} filters, their time and space efficient 
variants. 
In current work we derive such filters only for non-cycle transitions and 
single-edge cycles since the filters for transitions in multi-edge cycles 
are impractical to build/apply and abstract over, as they require the position 
of the considered event within a particular time interval.



Given an automaton $\cA$ for which we can derive a semantically equivalent  
relational query $Q_{\cA}$, the symbolic filter $F_X$ corresponding to one of 
its non-cycle transition $X$ is extensionally defined in terms of the events 
from the input that bind the event variable $X$ in the output of $Q_{\cA}$. 
Therefore $F_X$ can be obtained from $Q_{\cA}$ by projecting away (i.e.\ 
existentially quantifying) all the other event variables in its output besides 
$X$.

The symbolic filter $F_Y$ of a cycle transition $Y$, with node $k$ as source 
and destination, selects from the input those events that occur within interval 
$(t_Z, t_W)$, where $t_Z, t_W$, are the timestamps of a pair of event variables 
$Z, W$, from the output of $Q_{\cA}$ such that $Z, W$ are associated to 
non-cycle transitions entering and respectively exiting $k$.
In addition, $F_Y$ also enforces the guard $p_Y$ with its join predicates 
ignored, as they are guaranteed to be satisfied based on the fact that the 
nested query generated as part of the definition of $Q_W$ (and which includes 
$p_Y$) was found to hold during the evaluation of $Q_{\cA}$.

\begin{comment} 
The two kinds of transitions (cycle vs non-cycle) generate distinctly different 
kinds of symbolic filters. 
While both make use of the relational query $Q_{\cA}$ generated for the 
automaton, only the filter for cycle transitions makes direct use of its results
while the other simply uses $Q_{\cA}$'s expression as a starting point for its 
definition.
This distinction plays an important role in how we go about building these 
filters in a distributed environment.
\end{comment}


We take a bottom-up approach to building the symbolic filters as it allows us 
to outline an evaluation strategy that operates over sets and which uses set 
operations like union, intersection, set membership or emptiness testing. 
Adopting such a set-centric evaluation strategy is advantageous in a 
distributed environment due to the embarrassingly parallel nature of many set 
operators, but more importantly it gives us a powerful knob in terms of the set 
representations that we use, such that we can trade off precision in favor of 
performance. 
This strategy is what ultimately guides the design of the {\em abstract} 
filters (which we discuss in sections~\ref{sec:data_abstraction} 
and~\ref{sec:pred_abstraction}) which make our solution practical.
   

As a first step we build for every transition $X$ of an automaton $\cA$ so 
called "symbolic sets", which collect for every event matching the selection 
predicates of $p_X$ those fields of event variable $X$ referenced by join 
predicates throughout all the transition guards of $\cA$.
We then re-write the symbolic filters by replacing each event variable and 
selection predicate associated to a transition with its corresponding symbolic 
set.
Finally, the join predicates get re-written in terms of slicing, intersection 
and emptiness testing over these sets.


\subsection{Data abstraction}
\label{sec:data_abstraction}


Building the symbolic filters as described in the previous section is not a 
feasible option, as it would require at least just as much work as computing 
the final result.
Nonetheless, the symbolic filters provide an excellent template for designing 
appropriate set abstractions that can provide the set operations required for 
their constructing and querying them in a time and space efficient manner. 
Our approach is to use set abstractions that sacrifice precision, while 
remaining conservative, as we should never eliminate events that would 
otherwise have contributed to a successful match.
We call the resulting structures {\em abstract} filters as they are the outcome 
of employing several abstractions during the process outlined for deriving the 
symbolic filters.  


First of all, we remark that the sets we abstract over contain tuples as 
opposed to single values, where each tuple field holds the values relevant to a 
particular join predicate. 
Similarly, the abstractions we chose need to be multidimensional in the sense 
that they must allow the testing of the domain of values corresponding to a 
specific join predicate, independent of the others.  
Second, we note that besides supporting set intersection and set union, the 
choice for a particular set abstraction is deeply influenced by the particular 
kind of predicates said abstractions needs to support.
For example, in the case of equality joins an appropriate data abstraction 
would be to use bloom filters as they provide a low cost solution for testing 
whether o value belongs to a set, with the guarantee of no false negatives.
For enforcing inequality joins on the other hand, an interval map, i.e.\ a 
bitvector where each bit stands for a particular interval in the domain,
provides a similarly low cost abstraction.  




\subsection{Predicate abstraction}
\label{sec:pred_abstraction}


We propose {\em predicate abstraction}, ie.\ the technique of strengthening
 the
symbolic filters by discarding some of their predicates, as a way of
 overcoming
the challenges that can arise when turning symbolic filters into abstract 
filters.
For example, it may happen that for some predicate types
(for eg.\ $x.Contains(y)$, where $x$, $y$ are strings) we simply cannot
 provide
any data abstraction, and even for those that we can, materializing and
 querying
those data abstractions might prove too expensive.

Predicate abstraction is an essential component of our approach
allowing us to strike the right balance between the data reduction that the
symbolic filters provide on one hand, and the overheads introduced by their
data abstractions on the other.
For instance, we may choose to discard
predicates that have very low selectivity, i.e.\ the reduction in input 
data
that they provide does not justify the cost of enforcing them.
Similarly, one may turn to predicate abstraction when dealing with patterns
 with
a large number of join predicates or transitions, in order to mitigate the
increased overheads incurred by their data abstractions.

Considering that initial or final transitions typically have the fewest
number of matching events, one might choose to generate filters that only
consider the join predicates with respect to those transitions.
Due to the low cardinality of the sets of events matching these transitions 
the join predicates referencing them are likely to have very high 
selectivity.
Moreover, the data abstractions used to enforce them can achieve higher
precision for the same operating costs.




\subsection{Building filters through fixpoint}


We remark that the symbolic filters are not strictly tied to the ability to 
express automata as relational queries, but that they can also be obtained for 
an arbitrary automaton by using a fixpoint operator that keeps track of 
provenance information.
The fixpoint operator we consider assigns to the starting node the empty 
sequence and then iteratively builds for every node of the automaton its 
corresponding set of (partial) matches, until no more new matches are found. 
In every iteration, for each node $i$ and each of its outgoing transitions $X$, 
the partial matches added by the previous round to $i$ get extended if matching 
events are found within the symbolic set of $X$. 
The newly found matches then get added to the collection of matches 
corresponding to $X$'s destination, and the process starts over.  
Since we never remove partial matches we are guaranteed to reach a fixpoint.
Whenever we add a new match to an accepting node, we also update the symbolic 
filters of the transitions along the path followed by that match.

In designing the fixpoint operator we similarly make extensive use of sets and 
set operators.
In particular, the (partial) matches we compute for each node $i$ of the 
automaton are represented as a series of sets, one for each transition that may 
occur on a path from the start node to $i$.
Then the symbolic filter for a specific transition can be obtained by unioning 
its corresponding set across all the accepting nodes.
When deciding whether a partial match can be extended by triggering transition 
$X$ we simply intersect the symbolic set of $X$ with the projection from the 
partial match of all its fields that are joined in the guard of $X$.
If the result is empty then the extension is not possible, otherwise a new 
partial match gets created whose corresponding set for transition $X$ is the 
result of the intersection.   





 
