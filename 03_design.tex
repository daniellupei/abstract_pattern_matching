\section{Design}


We consider queries specified as a symbolic finite automaton where each
transition is annotated by a variable and a guard.
The variable is used to bind the fields of the currently considered event while 
the guard is a propositional formula in disjunctive normal form which decides 
whether the transition can be triggered or not.  
The atomic formulas of the guard are either {\em selection} predicates, which 
only reference the variable associated with the current transition,
or {\em join} predicates, which may also reference the variables of preceding 
transitions.
In particular, the guards of start transitions can only use selection 
predicates.  
   
Pattern matching algorithms require the input stream of events to be
(partially) sorted on time, while this is not always the case in practice due
to competing constraints of other stages in the data processing pipeline. 
Thus, evaluating pattern matching queries in a map-reduce framework usually 
adds a reduction step in order to sort the input, which can become the main 
bottleneck of the analysis, both at the network level (large amounts of 
shuffled data) and at the processing level (in case of data-skew).

The standard approach to minimize the cost of sorting/data shuffling has been 
to introduce a {\em preprocessing} phase which first filters the input based on 
the {\em selection} predicates in the transition guards, i.e.\ removes all 
events that do not satisfy the guard of at least one transition while ignoring 
its {\em join} predicates.
This {\em preprocessing} phase can significantly reduce both processing costs 
and latency since it takes linear time in the size of the input (as opposed to 
$O(nlogn)$ for sorting) and is embarrassingly parallel, i.e.\ scales out with 
the number of computing resources available.
Moreover, it can be merged with the previous operator in the data processing 
pipeline thus incurring no extra costs for materialization or data transfer.    


In our work we extend the opportunities for query plan optimizations across all 
the stages of the workload, beyond just pipelining the preprocessing phase of 
the pattern matcher, by leveraging the fact that a large class of symbolic 
finite automata have a corresponding relational calculus expression (possibly 
with counting quantifiers).
Whenever that is not the case we can narrow the scope of our optimizations to 
the sections of the pattern that do.
The resulting relational expressions can then be optimized within the scope of 
the entire (predominantly relational) workload based on decades of progress in 
relational optimizations.  
We remark that the translation to relational expressions is not limited only to 
acyclic symbolic automata, but also to automata with cycles of fixed length, 
i.e.\ each iteration of the cycle has the same number of transitions.
This class of symbolic automata is of particular importance as it includes the 
vast majority of patterns found in benchmarks and in industrial workloads.  


Even in the scenarios where the relational optimizer decides that using the 
pattern matcher leads to the most efficient query plan, we can leverage the 
relational expressions to generate a series of {\em abstract} filters that can 
dramatically increase the reduction ratio achieved by the preprocessing step by 
also taking advantage of the filtering power of {\em join} predicates (as 
opposed to just the {\em selection} predicates).   
Thus, in many cases we manage to discard most of the events that are guaranteed 
not to take part in a successful match and significantly reduce the amount of 
data fed into the pattern matcher.

We start from the relational formulas and produce {\em symbolic} filters for 
each transition, that retain only those events from the input which trigger 
that transition and take part in a complete match.
However in many cases these filters would be too expensive to build and 
evaluate as such.
Therefore, we coarsen them to obtain a set of {\em abstract} filters
that can be constructed and queried in a time and space efficient manner.
In particular, we make use of both {\em data} abstraction and {\em predicate} 
abstraction in order to generate filters that, while conservative, closely 
match the {\em symbolic} filters. 
We explore the trade-offs between the overheads incurred in building/querying
the filters and their accuracy. 


The derivation of abstract filters is not strictly tied to the ability to 
generate a semantically equivalent relational expression for a symbolic 
automaton. By adding the fixpoint construct, we are able to apply similar 
techniques to generate both the {\em symbolic} and the {\em abstract} 
filters.


\begin{comment}
We propose three levels of abstraction.
The first enforces the join constraints between different transitions as
expressed by join predicates within the transition guards.
The second one further imposes time windowing constraints (all events of a
successful match must occur within a timeout of the first event in the match).
Finally the last one enforces ordering constraints between {\em consecutive}
transitions of the pattern.
\end{comment}

\subsection{From automata to relational expressions}

We assume as input an automaton where each transition $X$ is annotated by a
guard $p_X$.
To streamline the presentation we begin by considering automata with only
cycles of length 1 and we distinguish between cycle transitions and
non-cycle transitions.

We formally define a symbolic finite automaton as $\cA = (S, T, )$ 

The translation process produces one query $Q_X$ per non-cycle transition $X$
and one query $Q_i$ per node $i$, excluding the initial node.
The transition queries $Q_X$ compute partial matches corresponding to the paths
ending with transition $X$.
Analogously, the node queries $Q_i$ produce partial matches corresponding to the
paths between the starting node and node $i$.
If a node $i$ is an accepting node then its query will return complete matches,
thus the final query of the automata is obtained by unioning all the queries
generated for the automata's accepting nodes.


The schema of these queries consists of a group of fields for each non-cycle
transition that may occur along its associated set of paths. If a transition is
triggered within a partial match then its corresponding group of fields records
the timestamp of the event that triggered it along with any other event
attributes that may be referenced by the predicates of succeeding transitions.
On the other hand, if a transition is not triggered in a particular partial
match then its group of fields is left void.


The translation process iterates in topological order over the nodes of the DAG
obtained by ignoring the cycle transitions of the automata.
At each node $i$, it first generates the queries for all its incoming
non-cycle transitions $Q_X$ and then $Q_i$ is defined as their union. 
The schema of $Q_i$ is established as the
union of the schemas of the incoming transitions $Q_X$, and the necessary tuple
mapping from the schema of $Q_X$ to the schema of $Q_i$ is also undergone.

The query for non-cycle transition $X$ with source node $k$ is generated as a
join between the partial matches produced by query $Q_k$ and the input
relation of events.
The possible event matches $e_X$ for transition $X$ are constrained based on the
transition's predicate $p_X$, and $e_X$'s timestamp which should be greater than
that of the latest event $e_k$ from the partial match computed by $Q_k$.
In addition, an inner query specifies that no other event should occur between
$e_k$ and $e_X$, apart from those matching a cycle transition on node $k$, if
such a transition should exist.



\subsection{Precise filter generation}
\label{sec:prec_filter_generation}

Based on the automata query $Q$ derived in the previous section we can generate
a set of precise filters, one per transition, such that if an event does not match
any of them, it is guaranteed not to contribute to any complete match.

The precise filter corresponding to a non-cycle transition $X$ is obtained from
$Q$ by projecting away (i.e.\ existentially quantifying) all the other transitions
from the complete match returned by $Q$.

For cycle transitions $Y$ on a node $k$ we define its precise filter as a
conjunction between 
a) the associated predicate $p_Y$ while existentially quantifying its join
attributes over the fields stored in the complete matches returned by $Q$, and
b) the time constraint specifying they should only occur between events matching
an incoming and an outgoing transition of $k$ within a complete match produced
by $Q$.

\subsection{Symbolic filters via data abstraction}
\label{sec:data_abstraction}


\subsection{Predicate abstraction}
\label{sec:pred_abstraction}


We propose {\em predicate abstraction}, ie.\ the technique of strengthening the
precise filters by discarding some of their predicates, as a way of overcoming
the challenges that can arise when turning precise filters into symbolic filters
via data abstraction.
For example, it may happen that for some predicate types
(for eg.\ $x.Contains(y)$, where $x$, $y$ are strings) we simply cannot provide
any data abstraction, and even for those that we can, materializing and querying
those data abstractions might prove too expensive.

Predicate abstraction is an essential component of our approach
allowing us to strike the right balance between the data reduction that the
symbolic filters provide on one hand, and the overheads introduced by their
data abstractions on the other.
For instance, we may choose to discard
predicates that have very low selectivity, i.e.\ the reduction in input data
that they provide does not justify the cost of enforcing them.
Similarly, one may turn to predicate abstraction when dealing with patterns with
a large number of join predicates or transitions, in order to mitigate the
increased overheads incurred by their data abstractions.

Considering that initial or final transitions typically have the fewest
number of matching events, one might choose to generate filters that only
consider the join predicates with respect to those transitions.
Due to the low cardinality of the sets of events matching these transitions 
the join predicates referencing them are likely to have very high selectivity.
Moreover, the data abstractions used to enforce them can achieve higher
precision for the same operating costs.












 
